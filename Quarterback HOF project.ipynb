{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408ab17f",
   "metadata": {},
   "source": [
    "<h1>NFL Quarterback Hall of Fame Predictor<h1>\n",
    "    <h2>Adam Yamarik<h2>\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b040325",
   "metadata": {},
   "source": [
    "The purpose of the model defined below is learn the statistics most important to making the Hall of Fame, and use that model to be able to predict whether a player will eventually make the HoF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f559c7e",
   "metadata": {},
   "source": [
    "This will be acomplished through both logistic regression, as well as applying a kernelized perceptron. The logistic regression model will also be used to learn the weights of the different features, which will be helpful in applying the kernelized perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73527c25",
   "metadata": {},
   "source": [
    "We start with the implementation of the logistic regression, but first, we need to import the data and translate it into something that we can work with. Each instance will be of the form:<br>\n",
    "Games played, completions, total pass attempts, total pass yards, total touchdowns, total interceptions, championchips, name<br>\n",
    "The name will not be of any use, and is just kept as a way to keep track of who is who. \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad007ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cell\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3f8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "\n",
    "xlabels = np.zeros((192, 7))\n",
    "ylabels = np.zeros(192)\n",
    "\n",
    "raw_data = open(\"xData.txt\")\n",
    "true_labels = open(\"yData.txt\")\n",
    "                      \n",
    "data = raw_data.read()\n",
    "labels = true_labels.read()\n",
    "\n",
    "splitData = data.splitlines()\n",
    "splitLabels = labels.splitlines()\n",
    "\n",
    "for i in range(0, 192):\n",
    "    currLine = splitData[i]\n",
    "\n",
    "    currArray = currLine.split(',')\n",
    "\n",
    "    for j in range(7):\n",
    "        \n",
    "        xlabels[i][j] = (int(currArray[j].strip()))\n",
    "        \n",
    "    \n",
    "        \n",
    "for i in range(0, 192):\n",
    "    ylabels[i] = int(splitLabels[i]) \n",
    "                \n",
    "        \n",
    "raw_data.close()\n",
    "true_labels.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d60094",
   "metadata": {},
   "source": [
    "Now with the data imported, we need to make a few modifications to the data. The whole point of this model is to predict if any quartarback will make the HoF. So there are some stats that would not be very helpful when making comparisons to those who are eligible to be in the Hall. Generally, these are total stats, like total completions, total touchdowns, etc. Comparing someone who has retired after 15 years, and someone who has only played 2 or 3 would make it near impossible to for the latter player to be predicted to make the Hall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b6201",
   "metadata": {},
   "source": [
    "For the specific changes, we can break them down by a per year, or even a per game basis. The smaller the scope, the better the comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09bca5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note; indecies for the stats are as follows:\n",
    "# 0: Total Games played; will be discarded for the reason described above\n",
    "# 1: Total Completions; Changed to completions per game\n",
    "# 2: Total Attempts; Changed to attempts per game\n",
    "# 3: Total Pass Yard; Changed to yards per game\n",
    "# 4: Total Passing TD; Changed to TD's per game\n",
    "# 5: Total Interceptions; Changed to int's per game\n",
    "# 6: Championchips; Unchanged\n",
    "\n",
    "newXData = np.zeros((192, 6))\n",
    "\n",
    "for i in range(0, 192):\n",
    "    compPerGame = (xlabels[i][1] / xlabels[i][0])\n",
    "    attPerGame = (xlabels[i][2] / xlabels[i][0])\n",
    "    yardsPerGame = (xlabels[i][3] / xlabels[i][0])\n",
    "    tdPerGame = (xlabels[i][4] / xlabels[i][0])\n",
    "    intPerGame = (xlabels[i][5] / xlabels[i][0])\n",
    "    \n",
    "    newXData[i][0] = compPerGame\n",
    "    newXData[i][1] = attPerGame\n",
    "    newXData[i][2] = yardsPerGame\n",
    "    newXData[i][3] = tdPerGame\n",
    "    newXData[i][4] = intPerGame\n",
    "    newXData[i][5] = xlabels[i][6]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75929b7d",
   "metadata": {},
   "source": [
    "The the data is in a form that can be used for our purposes. Now, we need to split the data, and run logistic regression on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64427df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into testing and training\n",
    "x_train, x_test, y_train, y_test = train_test_split(newXData, ylabels, test_size=.25, random_state=2)\n",
    "\n",
    "# Define the logistic regresion function\n",
    "logReg = LogisticRegression(penalty='l2', max_iter = 1000)\n",
    "\n",
    "logReg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464b7cb0",
   "metadata": {},
   "source": [
    "Now we can get the use the test set to see how well we did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd716b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(x_test)\n",
    "logReg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e81672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3498132",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logReg.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3a86eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n"
     ]
    }
   ],
   "source": [
    "score = logReg.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155ba236",
   "metadata": {},
   "source": [
    "Lets get the weight vector and analyze what the model says about the stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "710b3bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12354417  0.05243707  0.03272731  1.21452078 -0.03722771  1.54188867]]\n"
     ]
    }
   ],
   "source": [
    "weights = logReg.coef_\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4735321a",
   "metadata": {},
   "source": [
    "Lets proceed by breaking down the weights<br>\n",
    "Weights for feature 0, 1, and 2 are are pretty minimal. So according to the model, attempts, completions, and yards dont hold much importance to making the HoF. The last weight is championchips, which has a signigicant positive weight. This makes sense, since it is generally accepted that winning superbowls is the best way to leave your mark for the HoF. The weight for touchdowns is also significant. I find the interceptions to be interesting. While it does have a negative effect, it is very close to zero, so this model does not value interceptions highly for this prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7fb483",
   "metadata": {},
   "source": [
    "Now lets do a couple of tests and players which are not eligible for the HoF. Lets start with a player who is almost certianly be a first ballot Hall of Famer after he retires, Tom Bardy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12953376",
   "metadata": {},
   "outputs": [],
   "source": [
    "totGames = 318\n",
    "totComp = 7263\n",
    "totAtt = 11317\n",
    "totYards = 84520\n",
    "totTD = 624\n",
    "totInt = 203\n",
    "totChamp = 7\n",
    "\n",
    "compPG = totComp / totGames\n",
    "attPG = totAtt / totGames\n",
    "yardsPG = totYards / totGames\n",
    "tdPG = totTD / totGames\n",
    "intPG = totInt / totGames\n",
    "\n",
    "playerTomBrady = [[compPG, attPG, yardsPG, tdPG, intPG, totChamp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05cfffb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "predTB = logReg.predict(playerTomBrady)\n",
    "print(predTB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bfd513",
   "metadata": {},
   "source": [
    "As excpected, Tom Brady is predicted to make the Hall of Fame. Now lets test another likely candidate, Aaron Rodgers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5675bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "totGames = 213\n",
    "totComp = 4651\n",
    "totAtt = 9380\n",
    "totYards = 71940\n",
    "totTD = 449\n",
    "totInt = 93\n",
    "totChamp = 1\n",
    "\n",
    "compPG = totComp / totGames\n",
    "attPG = totAtt / totGames\n",
    "yardsPG = totYards / totGames\n",
    "tdPG = totTD / totGames\n",
    "intPG = totInt / totGames\n",
    "\n",
    "playerAaronRodgers = [[compPG, attPG, yardsPG, tdPG, intPG, totChamp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5001be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "predAR = logReg.predict(playerAaronRodgers)\n",
    "print(predAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4752c2",
   "metadata": {},
   "source": [
    "Once again, we see the model has the expected outcome. Now lets try the other side, a player who will most likely not make the HoF. We can test using Case Keenum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57a33fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "totGames = 76\n",
    "totComp = 1356\n",
    "totAtt = 2173\n",
    "totYards = 14876\n",
    "totTD = 78\n",
    "totInt = 48\n",
    "totChamp = 0\n",
    "\n",
    "compPG = totComp / totGames\n",
    "attPG = totAtt / totGames\n",
    "yardsPG = totYards / totGames\n",
    "tdPG = totTD / totGames\n",
    "intPG = totInt / totGames\n",
    "\n",
    "playerCaseKeenum = [[compPG, attPG, yardsPG, tdPG, intPG, totChamp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0d7aedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "predCK = logReg.predict(playerCaseKeenum)\n",
    "print(predCK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01554fd6",
   "metadata": {},
   "source": [
    "As expected, Kennum is prdeicted to not make the HoF. The above examples are pretty simple. Most people agree with the model, but what about players whose analyists and fans may have differing opinions about? Lets try the model on Eli Manning, perhaps the most controversial player in regards to this discussion. Eli has two superbowls, but never had been viewed as a top teir QB, so there is more ambiguity to whether he will make the HoF or not. For reference, the site which I got my data from, Pro Football Reference, includes a stat of their own, called Hall of Fame Monitor Score. This stat is their own way to predict the likelyhood of those players making the HoF. They put Eli Manning at 85.01. An average QB in the HoF has a score of 109. So Eli is a bit below that threashold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82048859",
   "metadata": {},
   "outputs": [],
   "source": [
    "totGames = 236\n",
    "totComp = 4895\n",
    "totAtt = 8119\n",
    "totYards = 57023\n",
    "totTD = 366\n",
    "totInt = 244\n",
    "totChamp = 2\n",
    "\n",
    "compPG = totComp / totGames\n",
    "attPG = totAtt / totGames\n",
    "yardsPG = totYards / totGames\n",
    "tdPG = totTD / totGames\n",
    "intPG = totInt / totGames\n",
    "\n",
    "playerEliManning = [[compPG, attPG, yardsPG, tdPG, intPG, totChamp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0928652e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "predEM = logReg.predict(playerEliManning)\n",
    "print(predEM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc5507",
   "metadata": {},
   "source": [
    "Interestingly, our model predicts the Eli Manning will make the Hall of Fame. Lets dig a little bit into why this is the case. Firstly, 2 superbowls is much higher than average, most QB's will not get anywhere close to a superbowl in their carrers, and the weight vector supports that, giving the highest weight to championchips feature. Our model also doesnt value inteceptions too highly, so the just over 1 int per game that Manning has doesnt negatively effect his probability for our model. <br>\n",
    "Since Eli is not eligible to be inducted to the HoF, we wont know whether the model is right for a while, and even if he does make it, it may be first ballot. Despite Manning being more abiguous in this discussion, I would say the models prediction is justifiable, but it would be justifiable if it predicted '0' as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494d7b4e",
   "metadata": {},
   "source": [
    "One last test. The Winner of the previous Super Bowl, Super Bowl 56, was the Los Angelos Rams. Their quarteback, Matthew Stafford, had high expectations placed on him after his trade from the Detroit Lions, and he lived up to them. But many people still believe that Stafford is not worthy of being in the Hall of Fame, so lets see what the model predicts. (For reference, Staffords Hall of Fame Monitor Score is at 68.44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f311800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "totGames = 182\n",
    "totComp = 4302\n",
    "totAtt = 6825\n",
    "totYards = 49995\n",
    "totTD = 323\n",
    "totInt = 161\n",
    "totChamp = 1\n",
    "\n",
    "compPG = totComp / totGames\n",
    "attPG = totAtt / totGames\n",
    "yardsPG = totYards / totGames\n",
    "tdPG = totTD / totGames\n",
    "intPG = totInt / totGames\n",
    "\n",
    "playerMattStafford = [[compPG, attPG, yardsPG, tdPG, intPG, totChamp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e7610dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "predMS = logReg.predict(playerMattStafford)\n",
    "print(predMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49edbcd5",
   "metadata": {},
   "source": [
    "Now lets use the weights to apply a kernelized perceptron to the data, and see how the two classifiers compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b51dc2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be9b3166",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightedXData = np.zeros((192,6))\n",
    "\n",
    "for i in range(0,192):\n",
    "    for j in range(0,6):\n",
    "        x = int(newXData[i][j])\n",
    "        currWeight = int(weights[0][j])\n",
    "        weightedXData[i][j] = x * currWeight\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52e8f976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into testing and training\n",
    "x_train, x_test, y_train, y_test = train_test_split(weightedXData, ylabels, test_size=.25, random_state=2)\n",
    "\n",
    "\n",
    "perceptron = SVC(kernel='poly')\n",
    "perceptron.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32340591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e78c6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3de5d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "perScore = perceptron.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "765569b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(perScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ccdeba",
   "metadata": {},
   "source": [
    "So we see that the score is a bit worse than the logistic regression, but that is ok. The kernelized perceptron still does a good job of predicting the data. I was curious to see what would occur if we used unweighted values, so I tested that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80782dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into testing and training\n",
    "x_train, x_test, y_train, y_test = train_test_split(newXData, ylabels, test_size=.25, random_state=2)\n",
    "\n",
    "\n",
    "perceptron2 = SVC(kernel='poly')\n",
    "perceptron2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdb7a81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fa90d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "perScore2 = perceptron2.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2a64fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7916666666666666\n"
     ]
    }
   ],
   "source": [
    "print(perScore2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d43691",
   "metadata": {},
   "source": [
    "We can see two interesting results from this. The first is that the unweighted data seems to more commonly be classified as a 0, whereas the weighted ones are a closer the the true split in the data. I fact, with the split given, none of the test values are classified as a 1 in the model. The second is that the unweighted values gives us a worse model with a lower score than the weighted one. So it seems using logistic regression to help taylor the features helped the perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425abc4e",
   "metadata": {},
   "source": [
    "Lets see if this model disagrees with the logistic regression one with the examples used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e0d02f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "totGames = 318\n",
    "totComp = 7263\n",
    "totAtt = 11317\n",
    "totYards = 84520\n",
    "totTD = 624\n",
    "totInt = 203\n",
    "totChamp = 7 * weights[0][5]\n",
    "\n",
    "compPG = (totComp / totGames) * weights[0][0]\n",
    "attPG = (totAtt / totGames) * weights[0][1]\n",
    "yardsPG = (totYards / totGames) * weights[0][2]\n",
    "tdPG = (totTD / totGames) * weights[0][3]\n",
    "intPG = (totInt / totGames) * weights[0][4]\n",
    "\n",
    "playerTomBrady = [[compPG, attPG, yardsPG, tdPG, intPG, totChamp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e7723ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "predTB = perceptron.predict(playerTomBrady)\n",
    "print(predTB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdba12a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "totGames = 213\n",
    "totComp = 4651\n",
    "totAtt = 9380\n",
    "totYards = 71940\n",
    "totTD = 449\n",
    "totInt = 93\n",
    "totChamp = 1 * weights[0][5]\n",
    "\n",
    "compPG = (totComp / totGames)  * weights[0][0]\n",
    "attPG = (totAtt / totGames) * weights[0][1]\n",
    "yardsPG = (totYards / totGames) * weights[0][2]\n",
    "tdPG = (totTD / totGames) * weights[0][3]\n",
    "intPG = (totInt / totGames) * weights[0][4]\n",
    "\n",
    "playerAaronRodgers = [[compPG, attPG, yardsPG, tdPG, intPG, totChamp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "820ee0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "predAR = perceptron.predict(playerAaronRodgers)\n",
    "print(predAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68257270",
   "metadata": {},
   "outputs": [],
   "source": [
    "totGames = 76\n",
    "totComp = 1356\n",
    "totAtt = 2173\n",
    "totYards = 14876\n",
    "totTD = 78\n",
    "totInt = 48\n",
    "totChamp = 0 * weights[0][5]\n",
    "\n",
    "compPG = totComp / totGames * weights[0][0]\n",
    "attPG = totAtt / totGames * weights[0][1]\n",
    "yardsPG = totYards / totGames * weights[0][2]\n",
    "tdPG = totTD / totGames * weights[0][3]\n",
    "intPG = totInt / totGames * weights[0][4]\n",
    "\n",
    "playerCaseKeenum = [[compPG, attPG, yardsPG, tdPG, intPG, totChamp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "881278dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "predCK = perceptron.predict(playerCaseKeenum)\n",
    "print(predCK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1462e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "totGames = 236\n",
    "totComp = 4895\n",
    "totAtt = 8119\n",
    "totYards = 57023\n",
    "totTD = 366\n",
    "totInt = 244\n",
    "totChamp = 2 * weights[0][5]\n",
    "\n",
    "compPG = (totComp / totGames) * weights[0][0]\n",
    "attPG = (totAtt / totGames) * weights[0][1]\n",
    "yardsPG = (totYards / totGames) * weights[0][2]\n",
    "tdPG = (totTD / totGames) * weights[0][3]\n",
    "intPG = (totInt / totGames) * weights[0][4]\n",
    "\n",
    "playerEliManning = [[compPG, attPG, yardsPG, tdPG, intPG, totChamp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cec3cbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "predEM = perceptron.predict(playerEliManning)\n",
    "print(predEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1bfd7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "totGames = 182\n",
    "totComp = 4302\n",
    "totAtt = 6825\n",
    "totYards = 49995\n",
    "totTD = 323\n",
    "totInt = 161\n",
    "totChamp = 1 * weights[0][5]\n",
    "\n",
    "compPG = totComp / totGames * weights[0][0]\n",
    "attPG = totAtt / totGames * weights[0][1]\n",
    "yardsPG = totYards / totGames * weights[0][2]\n",
    "tdPG = totTD / totGames * weights[0][3]\n",
    "intPG = totInt / totGames * weights[0][4]\n",
    "\n",
    "playerMattStafford = [[compPG, attPG, yardsPG, tdPG, intPG, totChamp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7822194b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "predMS = perceptron.predict(playerMattStafford)\n",
    "print(predMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29bb105",
   "metadata": {},
   "source": [
    "No chnages in the predictions. Lets try and see if we can find someone who is different between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67d6b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "totGames = 178\n",
    "totComp = 3771\n",
    "totAtt = 6108\n",
    "totYards = 41269\n",
    "totTD = 3227\n",
    "totInt = 144\n",
    "totChamp = 1\n",
    "\n",
    "compPG = totComp / totGames\n",
    "attPG = totAtt / totGames\n",
    "yardsPG = totYards / totGames\n",
    "tdPG = totTD / totGames\n",
    "intPG = totInt / totGames\n",
    "\n",
    "playerJoeFlacco= [[compPG, attPG, yardsPG, tdPG, intPG, totChamp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a20d447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "predJF = logReg.predict(playerJoeFlacco)\n",
    "print(predJF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bb52f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "totGames = 178\n",
    "totComp = 3771\n",
    "totAtt = 6108\n",
    "totYards = 41269\n",
    "totTD = 3227\n",
    "totInt = 144\n",
    "totChamp = 1 * weights[0][5]\n",
    "\n",
    "compPG = totComp / totGames * weights[0][0]\n",
    "attPG = totAtt / totGames * weights[0][1]\n",
    "yardsPG = totYards / totGames * weights[0][2]\n",
    "tdPG = totTD / totGames * weights[0][3]\n",
    "intPG = totInt / totGames * weights[0][4]\n",
    "\n",
    "playerJoeFlacco= [[compPG, attPG, yardsPG, tdPG, intPG, totChamp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6279d661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "predJF = perceptron.predict(playerJoeFlacco)\n",
    "print(predJF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "000e038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "totGames = 58\n",
    "totComp = 857\n",
    "totAtt = 1329\n",
    "totYards = 9967\n",
    "totTD = 84\n",
    "totInt = 31\n",
    "totChamp = 0\n",
    "\n",
    "compPG = totComp / totGames\n",
    "attPG = totAtt / totGames\n",
    "yardsPG = totYards / totGames\n",
    "tdPG = totTD / totGames\n",
    "intPG = totInt / totGames\n",
    "\n",
    "playerLamarJackson= [[compPG, attPG, yardsPG, tdPG, intPG, totChamp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bdf7f358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "predLJ = logReg.predict(playerLamarJackson)\n",
    "print(predLJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3db29354",
   "metadata": {},
   "outputs": [],
   "source": [
    "totGames = 58\n",
    "totComp = 857\n",
    "totAtt = 1329\n",
    "totYards = 9967\n",
    "totTD = 84\n",
    "totInt = 31\n",
    "totChamp = 0 * weights[0][5]\n",
    "\n",
    "compPG = totComp / totGames * weights[0][0]\n",
    "attPG = totAtt / totGames * weights[0][1]\n",
    "yardsPG = totYards / totGames * weights[0][2]\n",
    "tdPG = totTD / totGames * weights[0][3]\n",
    "intPG = totInt / totGames * weights[0][4]\n",
    "\n",
    "playerLamarJackson= [[compPG, attPG, yardsPG, tdPG, intPG, totChamp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e0c40e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "predLJ = perceptron.predict(playerLamarJackson)\n",
    "print(predLJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67f2b12",
   "metadata": {},
   "source": [
    "So Joe Flacco is predicted by both to make it, which is interesting in and of itself, but we have found a discrepency, in Lamar Jackson. Lamar is predicted to not make the Hall of Fame using the logistic regression model, and predicted to make the HoF. I think the majority of people would predict that Jacksons current time in the NLF is not enough to make the Hall of Fame. Much like our weights suggest, the best thing for him to do is to win a Super Bowl, but it is interesting to the see Jackson is a quarterback with this discrepency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcfa53c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
